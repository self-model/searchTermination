{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and manipulate data\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.warnings.filterwarnings('ignore')\n",
    "import difflib\n",
    "#notebook \n",
    "from IPython.core.debugger import set_trace\n",
    "from os import path as path\n",
    "import pdb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def noneToNaN(list):\n",
    "#     return [item if type(item)==float and item>100 and item<5000 else np.nan for item in list] \n",
    "\n",
    "# def getSubjData(subj_json, subj_id, group_list={}, search_types = ['shape', 'color', 'conjunction']):\n",
    "        \n",
    "#     estimates_dict = [d['estimates'] for d in subj_json if d['sender']=='meta search task'][0]\n",
    "#     estimates = np.array([estimates_dict[str(i)]/1000 for i in range(1,13)])\n",
    "\n",
    "#     timeToEstimate_dict = [d['timeToEstimate'] for d in subj_json if d['sender']=='meta search task'][0]\n",
    "#     timeToEstimate = np.array([np.nan if pd.isnull(timeToEstimate_dict[str(i)])\n",
    "#                                                   else timeToEstimate_dict[str(i)]/1000 for i in range(1,13)])\n",
    "\n",
    "#     accuracy_dict = [d['accuracy'] for d in subj_json if d['sender']=='Visual search task'][0]\n",
    "#     accuracy = np.array([accuracy_dict[str(i)] for i in range(1,13)]).flatten()\n",
    "    \n",
    "#     RT_dict = [d['RT'] for d in subj_json if d['sender']=='Visual search task'][0]\n",
    "#     RT= np.array([noneToNaN(RT_dict[str(i)]) for i in range(1,13)])\n",
    "#     RT = RT.flatten()/1000\n",
    "# #     RT[np.where(accuracy==False)]=np.nan\n",
    "\n",
    "#     subject_data = pd.DataFrame(np.array([estimates.repeat(3),timeToEstimate.repeat(3),RT, accuracy]).T, columns = ['estimates','timeToEstimate','RT','accuracy'])\n",
    "#     set_size = np.array([1,5,15,30]*3).repeat(3);\n",
    "#     search_type = np.array(search_types).repeat(12);\n",
    "#     subject_data['set_size']=set_size\n",
    "#     subject_data['search_type']=search_type\n",
    "# #     group_list[subj_id] = subject_data;\n",
    "    \n",
    "#     with open(path.join('..','data','batch3','jatos_results_20200113162056.txt')) as json_file:\n",
    "#     for i,line in enumerate(json_file):\n",
    "#         getSubjData(json.loads(line),i,group_list)\n",
    "\n",
    "def to_csv(filename):\n",
    "    dfs=[]\n",
    "    with open(filename+'.txt') as json_file:\n",
    "        for i,line in enumerate(json_file):\n",
    "            if line[0:14]!='Consent given.':\n",
    "                dfs.append(pd.read_json(line))\n",
    "            \n",
    "\n",
    "    group_df = pd.concat(dfs)\n",
    "    group_df.to_csv(filename+'.csv', index=False)\n",
    "\n",
    "\n",
    "# dfs = []\n",
    "# with open(path.join('..','Experiments','Lotz','results','pilot_rand_assign','jatos_results_batch1.txt')) as json_file:\n",
    "#     for i,line in enumerate(json_file):\n",
    "#         if line[0:14]!='Consent given.':\n",
    "#             dfs.append(pd.read_json(line))\n",
    "            \n",
    "\n",
    "# group_df = pd.concat(dfs)\n",
    "# group_df.to_csv(path.join('..','Experiments','Lotz','results','pilot_rand_assign','jatos_results_batch1.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_csv(path.join('..','Experiments','change_detection','results','pilot4','jatos_results_batch1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27     {\"Q0\":\"Predict when the picture of a cat will ...\n",
       "126                            {\"Q0\":\"I liked the cat!\"}\n",
       "27     {\"Q0\":\"J when you think a cat will appear, F w...\n",
       "126                                            {\"Q0\":\"\"}\n",
       "39                    {\"Q0\":\"f - no cat\\nj - yes cat\\n\"}\n",
       "                             ...                        \n",
       "126                                            {\"Q0\":\"\"}\n",
       "27     {\"Q0\":\"shapes are shown and for some shapes a ...\n",
       "126                                            {\"Q0\":\"\"}\n",
       "27     {\"Q0\":\"j if the cat will appear and f if i thi...\n",
       "126                                            {\"Q0\":\"\"}\n",
       "Name: responses, Length: 122, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_df[group_df.trial_type=='survey-text'].responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' The study was very well laid out and I appreciate the practice rounds to give me the confidence I understood your instructions prior to starting!',\n",
       " ' ',\n",
       " ' As the trial went on it got harder because the two letters looked like they combined into one so I struggled to choose the right one.',\n",
       " ' A couple of mistakes i made on the box trials was where i had pressed the wrong key by mistake ',\n",
       " ' ',\n",
       " ' ',\n",
       " '',\n",
       " ' ',\n",
       " ' ',\n",
       " ' I have dyslexia which affects my working memory and how fast I process things.',\n",
       " ' all good! thanks. should be breathe not breath ',\n",
       " ' Interesting',\n",
       " \" Took a while to understand what I needed to do. The flashing letters were so fast that I didn't' notice them.\",\n",
       " ' my eyes were getting tired by the end, but I had found my flow more and was more acclimatised to the task',\n",
       " ' ',\n",
       " ' n/a',\n",
       " ' For the test I did not realise how to change the size of the circle - but I did for the actual experiment',\n",
       " \" I'm not sure if the instructions were correct on the first part of the test. I recall it asked us to say if the second letter was an O or an Q rather than the first? Confused me slightly.\\nIn general liked the test. I have done a lot of these things and the presentation was amongst the best I've seen.\",\n",
       " 'There was a typo on the first trial',\n",
       " 'everything was fine ',\n",
       " ' Good Study ',\n",
       " ' N/A',\n",
       " ' It was flashing too quickly for the second trial. It was literally impossible to know whether it was a Q or an O with it flashing so quickly. ',\n",
       " ' ',\n",
       " ' The letter in the second test flashed up VERY quick!',\n",
       " ' I did not realise how much I would have to really concentrate to look and see if it was a Q or an O. It was very interesting. ',\n",
       " ' ',\n",
       " ' It was interesting how quickly I fatigued!!!',\n",
       " ' ',\n",
       " 'N/A']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feedback_list = []\n",
    "# feedback= json.loads(group_df.loc[group_df.trial_type=='survey-text']['responses'].iloc[0])['worker_comments']\n",
    "# feedback\n",
    "[json.loads(a)['worker_comments'] for a in group_df.loc[group_df.trial_type=='survey-text']['responses'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "with open(path.join('..','Experiments','Newman1980','results','3_item_pilot','jatos_results_batch1.txt'),encoding='utf-8-sig') as json_file:\n",
    "    for i,line in enumerate(json_file):\n",
    "        if line[0:14]!='Consent given.':\n",
    "            dfs.append(pd.read_json(line))\n",
    "            \n",
    "\n",
    "group_df = pd.concat(dfs)\n",
    "group_df.to_csv(path.join('..','Experiments','Newman1980','results','3_item_pilot','jatos_results_batch1.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Tried to predict a pattern in terms of colour sequencing but didn't really work.\",\n",
       " 'I tried very hard but 5 seconds was way too quick for me to process the possible patterns.',\n",
       " '',\n",
       " 'The only distraction would of been my 3 year old little girl playing in the lounge.',\n",
       " 'Everything was great! I hope my contribution will help.',\n",
       " 'i think that was funny and challenging',\n",
       " 'its very interesting',\n",
       " '',\n",
       " \"It was interesting to see how my brain was working on figuring out the 'difference' between red and white cards.\",\n",
       " '',\n",
       " 'It was extremely unpredictable exercise.',\n",
       " '',\n",
       " 'It was actually a fun test to take. I also loved that it showed the number of picture i was on',\n",
       " 'hard to spot a pattern with only 5s to think - guess that is the point of the experiment though',\n",
       " 'it was an interesting experiment, i havent participated at something similar before',\n",
       " 'I have a lot of fun making decisions.']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [json.loads(a)['worker_comments'] for a in group_df.loc[group_df.trial_type=='survey-text']['responses'].tolist()]\n",
    "\n",
    "[json.loads(a)['worker_comments'] for a in group_df.loc[group_df.internal_node_id=='0.0-7.0']['responses'].tolist()]\n",
    "# [json.loads(a)['best_guess'] for a in group_df.loc[group_df.internal_node_id=='0.0-6.0']['responses'].tolist()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>success</th>\n",
       "      <th>trial_type</th>\n",
       "      <th>trial_index</th>\n",
       "      <th>time_elapsed</th>\n",
       "      <th>internal_node_id</th>\n",
       "      <th>STUDY_ID</th>\n",
       "      <th>PROLIFIC_PID</th>\n",
       "      <th>SESSION_ID</th>\n",
       "      <th>FP</th>\n",
       "      <th>bonus</th>\n",
       "      <th>draw_light</th>\n",
       "      <th>RT</th>\n",
       "      <th>response</th>\n",
       "      <th>correct_response</th>\n",
       "      <th>test_part</th>\n",
       "      <th>correct</th>\n",
       "      <th>rt</th>\n",
       "      <th>responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>fullscreen</td>\n",
       "      <td>0</td>\n",
       "      <td>6582</td>\n",
       "      <td>0.0-0.0</td>\n",
       "      <td>5f004f090329ec14b5f49015</td>\n",
       "      <td>5e6a73aa9ee0c9029a2986d4</td>\n",
       "      <td>5f00501fe3700a000b6b8c57</td>\n",
       "      <td>False</td>\n",
       "      <td>0.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>p5Text</td>\n",
       "      <td>1</td>\n",
       "      <td>18187</td>\n",
       "      <td>0.0-1.0</td>\n",
       "      <td>5f004f090329ec14b5f49015</td>\n",
       "      <td>5e6a73aa9ee0c9029a2986d4</td>\n",
       "      <td>5f00501fe3700a000b6b8c57</td>\n",
       "      <td>False</td>\n",
       "      <td>0.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>p5Text</td>\n",
       "      <td>2</td>\n",
       "      <td>25645</td>\n",
       "      <td>0.0-2.0</td>\n",
       "      <td>5f004f090329ec14b5f49015</td>\n",
       "      <td>5e6a73aa9ee0c9029a2986d4</td>\n",
       "      <td>5f00501fe3700a000b6b8c57</td>\n",
       "      <td>False</td>\n",
       "      <td>0.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>p5Text</td>\n",
       "      <td>3</td>\n",
       "      <td>34829</td>\n",
       "      <td>0.0-3.0</td>\n",
       "      <td>5f004f090329ec14b5f49015</td>\n",
       "      <td>5e6a73aa9ee0c9029a2986d4</td>\n",
       "      <td>5f00501fe3700a000b6b8c57</td>\n",
       "      <td>False</td>\n",
       "      <td>0.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>p5Text</td>\n",
       "      <td>4</td>\n",
       "      <td>45256</td>\n",
       "      <td>0.0-4.0</td>\n",
       "      <td>5f004f090329ec14b5f49015</td>\n",
       "      <td>5e6a73aa9ee0c9029a2986d4</td>\n",
       "      <td>5f00501fe3700a000b6b8c57</td>\n",
       "      <td>False</td>\n",
       "      <td>0.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>NaN</td>\n",
       "      <td>p5card</td>\n",
       "      <td>183</td>\n",
       "      <td>417954</td>\n",
       "      <td>0.0-5.0-0.89</td>\n",
       "      <td>5f004f090329ec14b5f49015</td>\n",
       "      <td>5e6a73aa9ee0c9029a2986d4</td>\n",
       "      <td>5f00501fe3700a000b6b8c57</td>\n",
       "      <td>False</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1607.87</td>\n",
       "      <td>j</td>\n",
       "      <td>j</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>NaN</td>\n",
       "      <td>p5feedback</td>\n",
       "      <td>184</td>\n",
       "      <td>420098</td>\n",
       "      <td>0.0-5.0-1.89</td>\n",
       "      <td>5f004f090329ec14b5f49015</td>\n",
       "      <td>5e6a73aa9ee0c9029a2986d4</td>\n",
       "      <td>5f00501fe3700a000b6b8c57</td>\n",
       "      <td>False</td>\n",
       "      <td>0.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>NaN</td>\n",
       "      <td>survey-text</td>\n",
       "      <td>185</td>\n",
       "      <td>458790</td>\n",
       "      <td>0.0-6.0</td>\n",
       "      <td>5f004f090329ec14b5f49015</td>\n",
       "      <td>5e6a73aa9ee0c9029a2986d4</td>\n",
       "      <td>5f00501fe3700a000b6b8c57</td>\n",
       "      <td>False</td>\n",
       "      <td>0.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38685.910</td>\n",
       "      <td>{\"best_guess\":\" if there was a smoke in the pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>NaN</td>\n",
       "      <td>survey-text</td>\n",
       "      <td>186</td>\n",
       "      <td>462798</td>\n",
       "      <td>0.0-7.0</td>\n",
       "      <td>5f004f090329ec14b5f49015</td>\n",
       "      <td>5e6a73aa9ee0c9029a2986d4</td>\n",
       "      <td>5f00501fe3700a000b6b8c57</td>\n",
       "      <td>False</td>\n",
       "      <td>0.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4005.685</td>\n",
       "      <td>{\"worker_comments\":\"\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>NaN</td>\n",
       "      <td>p5Text</td>\n",
       "      <td>187</td>\n",
       "      <td>471548</td>\n",
       "      <td>0.0-8.0</td>\n",
       "      <td>5f004f090329ec14b5f49015</td>\n",
       "      <td>5e6a73aa9ee0c9029a2986d4</td>\n",
       "      <td>5f00501fe3700a000b6b8c57</td>\n",
       "      <td>False</td>\n",
       "      <td>0.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     success   trial_type  trial_index  time_elapsed internal_node_id  \\\n",
       "0        1.0   fullscreen            0          6582          0.0-0.0   \n",
       "1        NaN       p5Text            1         18187          0.0-1.0   \n",
       "2        NaN       p5Text            2         25645          0.0-2.0   \n",
       "3        NaN       p5Text            3         34829          0.0-3.0   \n",
       "4        NaN       p5Text            4         45256          0.0-4.0   \n",
       "..       ...          ...          ...           ...              ...   \n",
       "183      NaN       p5card          183        417954     0.0-5.0-0.89   \n",
       "184      NaN   p5feedback          184        420098     0.0-5.0-1.89   \n",
       "185      NaN  survey-text          185        458790          0.0-6.0   \n",
       "186      NaN  survey-text          186        462798          0.0-7.0   \n",
       "187      NaN       p5Text          187        471548          0.0-8.0   \n",
       "\n",
       "                     STUDY_ID              PROLIFIC_PID  \\\n",
       "0    5f004f090329ec14b5f49015  5e6a73aa9ee0c9029a2986d4   \n",
       "1    5f004f090329ec14b5f49015  5e6a73aa9ee0c9029a2986d4   \n",
       "2    5f004f090329ec14b5f49015  5e6a73aa9ee0c9029a2986d4   \n",
       "3    5f004f090329ec14b5f49015  5e6a73aa9ee0c9029a2986d4   \n",
       "4    5f004f090329ec14b5f49015  5e6a73aa9ee0c9029a2986d4   \n",
       "..                        ...                       ...   \n",
       "183  5f004f090329ec14b5f49015  5e6a73aa9ee0c9029a2986d4   \n",
       "184  5f004f090329ec14b5f49015  5e6a73aa9ee0c9029a2986d4   \n",
       "185  5f004f090329ec14b5f49015  5e6a73aa9ee0c9029a2986d4   \n",
       "186  5f004f090329ec14b5f49015  5e6a73aa9ee0c9029a2986d4   \n",
       "187  5f004f090329ec14b5f49015  5e6a73aa9ee0c9029a2986d4   \n",
       "\n",
       "                   SESSION_ID     FP  bonus  draw_light       RT response  \\\n",
       "0    5f00501fe3700a000b6b8c57  False   0.69         NaN      NaN      NaN   \n",
       "1    5f00501fe3700a000b6b8c57  False   0.69         NaN      NaN      NaN   \n",
       "2    5f00501fe3700a000b6b8c57  False   0.69         NaN      NaN      NaN   \n",
       "3    5f00501fe3700a000b6b8c57  False   0.69         NaN      NaN      NaN   \n",
       "4    5f00501fe3700a000b6b8c57  False   0.69         NaN      NaN      NaN   \n",
       "..                        ...    ...    ...         ...      ...      ...   \n",
       "183  5f00501fe3700a000b6b8c57  False   0.69         1.0  1607.87        j   \n",
       "184  5f00501fe3700a000b6b8c57  False   0.69         NaN      NaN      NaN   \n",
       "185  5f00501fe3700a000b6b8c57  False   0.69         NaN      NaN      NaN   \n",
       "186  5f00501fe3700a000b6b8c57  False   0.69         NaN      NaN      NaN   \n",
       "187  5f00501fe3700a000b6b8c57  False   0.69         NaN      NaN      NaN   \n",
       "\n",
       "    correct_response test_part  correct         rt  \\\n",
       "0                NaN       NaN      NaN        NaN   \n",
       "1                NaN       NaN      NaN        NaN   \n",
       "2                NaN       NaN      NaN        NaN   \n",
       "3                NaN       NaN      NaN        NaN   \n",
       "4                NaN       NaN      NaN        NaN   \n",
       "..               ...       ...      ...        ...   \n",
       "183                j      test      1.0        NaN   \n",
       "184              NaN       NaN      NaN        NaN   \n",
       "185              NaN       NaN      NaN  38685.910   \n",
       "186              NaN       NaN      NaN   4005.685   \n",
       "187              NaN       NaN      NaN        NaN   \n",
       "\n",
       "                                             responses  \n",
       "0                                                  NaN  \n",
       "1                                                  NaN  \n",
       "2                                                  NaN  \n",
       "3                                                  NaN  \n",
       "4                                                  NaN  \n",
       "..                                                 ...  \n",
       "183                                                NaN  \n",
       "184                                                NaN  \n",
       "185  {\"best_guess\":\" if there was a smoke in the pi...  \n",
       "186                             {\"worker_comments\":\"\"}  \n",
       "187                                                NaN  \n",
       "\n",
       "[188 rows x 18 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_json(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
